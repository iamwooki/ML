{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_GradientDescent.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0kqelTMBgh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "#버전 2.0으로 업그레이드됨에 따라 v1과 호환이 되지 않음"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KG-QknDEDVbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_data = [1,2,3]\n",
        "y_data = [1,2,3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkoWOf6qDh97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W = tf.Variable(tf.random_normal([1]), name='weight') #임의로 바꿔가면서 판단하기 위해 placeholder\n",
        "X = tf.placeholder(tf.float32)\n",
        "Y = tf.placeholder(tf.float32)\n",
        "\n",
        "hypothesis = W * X # H(x) = Wx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1t_LcXUEVlI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cost/loss function\n",
        "cost = tf.reduce_sum(tf.square(hypothesis-Y)) # cost(W) = 1/m Sigma_i=1 ^ m (Wx^i - y^i)^2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11yNCpwOWlHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-- case 1 --\n",
        "#Minimize: Gradient Descent using derivative \n",
        "#W-= Learing_rate * derivative => W:= W-a * 1/m * Sigma_i=1 ^ m (Wx^i-y^i)*x^i\n",
        "learning_rate = 0.1 # a\n",
        "gradient = tf.reduce_mean((W* X - Y) * X)\n",
        "#위의 gradient의 경우 식이 간단해서 직접 입력해줬지만 그렇지 않은 경우 case2와 같이 사용\n",
        "descent = W - learning_rate * gradient\n",
        "update = W.assign(descent)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUC1Bhh8W0Wr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "37526d46-24f4-490e-ef02-8fc8c571b3c5"
      },
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "for step in range(21):\n",
        "  sess.run(update, feed_dict={X: x_data, Y: y_data})\n",
        "  print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.44475186 [0.82176423]\n",
            "1 0.12650721 [0.9049409]\n",
            "2 0.03598421 [0.94930184]\n",
            "3 0.010235544 [0.97296095]\n",
            "4 0.0029114408 [0.9855792]\n",
            "5 0.00082813634 [0.9923089]\n",
            "6 0.0002355604 [0.99589807]\n",
            "7 6.700621e-05 [0.9978123]\n",
            "8 1.9058218e-05 [0.99883324]\n",
            "9 5.4211228e-06 [0.9993777]\n",
            "10 1.5420082e-06 [0.9996681]\n",
            "11 4.3886047e-07 [0.999823]\n",
            "12 1.247954e-07 [0.9999056]\n",
            "13 3.5532185e-08 [0.99994963]\n",
            "14 1.0107147e-08 [0.9999731]\n",
            "15 2.893973e-09 [0.99998564]\n",
            "16 8.1490725e-10 [0.9999924]\n",
            "17 2.2998847e-10 [0.99999595]\n",
            "18 6.446044e-11 [0.99999785]\n",
            "19 1.7553958e-11 [0.99999887]\n",
            "20 5.4143356e-12 [0.9999994]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-4_4DWcaiJl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bcc1fca1-f3b5-4b19-a990-49913f75bbab"
      },
      "source": [
        "#case 2\n",
        "X=[1,2,3]\n",
        "Y=[1,2,3]\n",
        "W= tf.Variable(5.0)\n",
        "hypothesis = W * X # H(x) = Wx\n",
        "\n",
        "cost = tf.reduce_mean(tf.square(hypothesis-Y))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
        "train = optimizer.minimize(cost)\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for step in range(100):\n",
        "  print(step, sess.run(W))\n",
        "  sess.run(train)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 5.0\n",
            "1 1.2666664\n",
            "2 1.0177778\n",
            "3 1.0011852\n",
            "4 1.000079\n",
            "5 1.0000052\n",
            "6 1.0000004\n",
            "7 1.0\n",
            "8 1.0\n",
            "9 1.0\n",
            "10 1.0\n",
            "11 1.0\n",
            "12 1.0\n",
            "13 1.0\n",
            "14 1.0\n",
            "15 1.0\n",
            "16 1.0\n",
            "17 1.0\n",
            "18 1.0\n",
            "19 1.0\n",
            "20 1.0\n",
            "21 1.0\n",
            "22 1.0\n",
            "23 1.0\n",
            "24 1.0\n",
            "25 1.0\n",
            "26 1.0\n",
            "27 1.0\n",
            "28 1.0\n",
            "29 1.0\n",
            "30 1.0\n",
            "31 1.0\n",
            "32 1.0\n",
            "33 1.0\n",
            "34 1.0\n",
            "35 1.0\n",
            "36 1.0\n",
            "37 1.0\n",
            "38 1.0\n",
            "39 1.0\n",
            "40 1.0\n",
            "41 1.0\n",
            "42 1.0\n",
            "43 1.0\n",
            "44 1.0\n",
            "45 1.0\n",
            "46 1.0\n",
            "47 1.0\n",
            "48 1.0\n",
            "49 1.0\n",
            "50 1.0\n",
            "51 1.0\n",
            "52 1.0\n",
            "53 1.0\n",
            "54 1.0\n",
            "55 1.0\n",
            "56 1.0\n",
            "57 1.0\n",
            "58 1.0\n",
            "59 1.0\n",
            "60 1.0\n",
            "61 1.0\n",
            "62 1.0\n",
            "63 1.0\n",
            "64 1.0\n",
            "65 1.0\n",
            "66 1.0\n",
            "67 1.0\n",
            "68 1.0\n",
            "69 1.0\n",
            "70 1.0\n",
            "71 1.0\n",
            "72 1.0\n",
            "73 1.0\n",
            "74 1.0\n",
            "75 1.0\n",
            "76 1.0\n",
            "77 1.0\n",
            "78 1.0\n",
            "79 1.0\n",
            "80 1.0\n",
            "81 1.0\n",
            "82 1.0\n",
            "83 1.0\n",
            "84 1.0\n",
            "85 1.0\n",
            "86 1.0\n",
            "87 1.0\n",
            "88 1.0\n",
            "89 1.0\n",
            "90 1.0\n",
            "91 1.0\n",
            "92 1.0\n",
            "93 1.0\n",
            "94 1.0\n",
            "95 1.0\n",
            "96 1.0\n",
            "97 1.0\n",
            "98 1.0\n",
            "99 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZITzsUfcR_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Optional compute_gradient and apply gradient\n",
        "\n",
        "X=[1,2,3]\n",
        "Y=[1,2,3]\n",
        "W= tf.Variable(5.0)\n",
        "hypothesis = W * X # H(x) = Wx\n",
        "\n",
        "gradient = tf.reduce_mean((W* X-Y)*X) *2 \n",
        "\n",
        "cost = tf.reduce_mean(tf.square(hypothesis-Y))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
        "\n",
        "# get gradients\n",
        "gvs = optimizer.compute_gradients(cost)\n",
        "# gvs 수정\n",
        "apply_graidents = optimizer.apply_gradients(gvs)\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for step in range(100):\n",
        "  print(step, sess.run( [gradient, W, gvs]))\n",
        "  sess.run(apply_graidents)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}